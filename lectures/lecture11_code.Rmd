---
title: "Lecture 11: k-Nearest Neighbors"
author: "STAT 452, Spring 2021"
output: html_document
---

To demonstrate the kNN algorithm we use a data set from the `palmerpenguins` R package.  You can read about this data set here: 

https://allisonhorst.github.io/palmerpenguins/articles/intro.html

The website also has a bunch of neat artwork!

The goal of this analysis is to use kNN to predict the species of penguin based on measurements of the bill and flipper length.


```{r, message = FALSE}
library(palmerpenguins)
library(tidyverse)
library(class) # library with knn function
```

```{r}
glimpse(penguins)
```


```{r}
table(penguins$species)
```

```{r}
ggplot(penguins, aes(x=flipper_length_mm, y=bill_length_mm, color = species)) +
  geom_point()
```

# Prepare Data

```{r}
# function to standardize numeric predictors between 0 and 1
standardize <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}
```

```{r}
# test function
standardize(x = 1:5)
```

Next we standardize the two predictors (flipper and bill length) between 0 and 1, and remove any missing data.
```{r}
penguins2 <- penguins %>%
  select(species, flipper_length_mm, bill_length_mm) %>%
  na.omit() %>%
  mutate(flipper_length = standardize(flipper_length_mm)) %>%
  mutate(bill_length = standardize(bill_length_mm)) %>%
  select(-flipper_length_mm, -bill_length_mm)
```

```{r}
penguins2
```


```{r}
summary(penguins2)
```



# Cross-Validation

Next we use the hold-out method to perform cross-validation, and split the data into a 70\% training and 30\% test set.  

The `knn()` function from the `class` package can be used to implement the algorithm and make predictions for the classes (penguin species) on the test set.  We'll compute the confusion matrix and accuracy of the kNN classifier when $k=1,3,5$.

```{r}
# split data into a training and test set
set.seed(123)
n <- nrow(penguins2)
train_index <- sample(1:n, round(0.7*n))
X_train <- penguins2[train_index, 2:3]
X_test <- penguins2[-train_index, 2:3]
y_train <- penguins2$species[train_index]
y_test <- penguins2$species[-train_index]
```

### k = 1

```{r}
# run kNN with k=1
knn1_pred <- knn(X_train, X_test, y_train, k=1)
```

```{r}
# make confusion matrix
tb <- table(predicted = knn1_pred, actual = y_test)
addmargins(tb)
```

```{r}
# compute accuracy
(47 + 15 + 36) / 103
```

### k = 3

```{r}
# run kNN with k=3
knn3_pred <- knn(X_train, X_test, y_train, k=3)
```

```{r}
# make confusion matrix
tb <- table(predicted = knn3_pred, actual = y_test)
addmargins(tb)
```

```{r}
# compute accuracy
(46 + 14 + 36) / 103
```

### k = 5

```{r}
# run kNN with k=5
knn5_pred <- knn(X_train, X_test, y_train, k=5)
```

```{r}
# make confusion matrix
tb <- table(predicted = knn5_pred, actual = y_test)
addmargins(tb)
```

```{r}
# compute accuracy
(46 + 14 + 36) / 103
```

The overall accuracy does not change much for the different values of $k$.  Using $k=1$ resulted in the highest accuracy.






